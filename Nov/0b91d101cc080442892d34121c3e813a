LONDON: Ofcom will soon be given the power to impose fines of up to £18 million ($25 million), or 10 percent of annual turnover, on big tech companies that fail to protect their users from online harm. The UK government-approved regulator for broadcasting and telecommunications has warned that the business models of social media companies are inherently harmful to users. “It’s certainly true that some of the things at the heart of the business models at the moment, such as ‘recommend’ algorithms and that link with advertising revenue, those business models have driven huge scale, huge growth, huge revenues — and some of those design features are also at the root of the problem we have with safety and harm,” said Dame Melanie Dawes, chief executive of Ofcom. She said that efforts to regulate Big Tech had to address the fact that companies such as Facebook and Twitter have strong incentives to continue to allow users to post hateful content on their platforms. This comes as a response to the recent revelations surrounding Facebook and the leaked documents proving that the tech giant was aware of Instagram’s harmful effect on teenage girls. Former Facebook data scientist turned whistleblower Frances Haugen said last month that the company is making online hate and extremism worse and outlined how it could improve online safety. She urged CEO of Facebook, Mark Zuckerberg, to step down and allow change rather than devoting resources to a rebrand. Facebook, which recently rebranded as Meta, will begin focusing on building the “metaverse,” a shared virtual environment that it bets will be the successor to the mobile Internet.